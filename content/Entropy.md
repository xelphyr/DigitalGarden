---
title: Entropy
firstDate: 3rd Jul, 2024
draft: true
tags:
  - "#ZP"
  - chemistry
---
>[!Definition] 
>It is the number of possible arrangements of a system.
>To put it simply, it is a measure of randomness in a system.

 Entropy $\uparrow$ when ways of arranging a system $\uparrow$.
 A real-life example of entropy is [[diffusion]].
 
## Chemistry
In a reaction: 
- The total entropy is equal to the entropy of the system + the entropy of the surroundings:
$$\Delta S_{total} = \Delta S_{system}+\Delta S_{surroundings} $$
 - The entropy within a system is equal to the sum of entropies of reactants subtracted from the sum of entropies of products  
 $$\Delta S_{sys}=\Sigma S_{prod}-\Sigma S_{reactants}$$
- The entropy of the surroundings is defined as the following:
$$\Delta S_{surr}=-\frac{\Delta H_{reaction}}{T}$$
>[!Important]
>Any reaction must have an increase in entropy after the reaction is complete (see [[Second Law of Thermodynamics]]), hence:
>
>If $\Delta S_{total}$ is not -ve ($i.e. \ge0$), then the forward reaction is feasible
>If $\Delta S_{total}$ is -ve ($i.e.  < 0$), then forward reaction is infeasible

# Related Notes


# Literary (Further Reading)
